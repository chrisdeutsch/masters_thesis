% ~ 12 pages
\chapter{Identification of Hadronic Tau Lepton Decays using Boosted Decision
  Trees}
\label{sec:bdt}
The reconstruction of hadronic tau lepton decays described in
Chapter~\ref{sec:reconstruction} is based on jets reconstructed using the
anti-$k_t$ jet algorithm operating on clusters of calorimeter cells. Jets
originating from quarks or gluons, which are more abundant than tau leptons due
to the large multijet production cross section at the LHC, are generally
reconstructed as candidates for hadronic tau lepton decays and represent a
significant background in many analyses. Other processes, e.g.\
$W{+}\text{jets}$, exist that can fake \tauhadvis. The reconstruction itself
offers little rejection of \tauhadvis candidates from quark- or gluon-initiated
jets with the exception of the track classification when requiring 1- or 3-track
decays. In the ATLAS experiment an identification algorithm based on
multivariate methods utilising track and shower shape
variables~\cite{atlas:taurec:run1, atlas:taurec:run2} is used to discriminate
hadronic tau decays from \tauhadvis candidates originating from jets. The
algorithm has been continuously developed since Run 1 of the LHC.

This chapter starts with a description of the tau identification procedure
including definitions of the discriminating variables and the configuration of
the BDTs used for distinguishing real \tauhadvis candidates (signal candidates)
and \tauhadvis candidates originating from quark- or gluon-initiated jets
(background candidates). Samples used for optimisation and performance
comparison, the kinematic reweighting and the preselection will be described.
Subsequently, a systematic optimisation of the BDT is performed to improve the
discriminative power of tau identification. For this the configuration of the
BDT and the variable selection is investigated. The chapter is concluded by
evaluating the performance of the optimised BDTs and comparing it to the
preceding configuration.

The following figures of merit are used to describe the performance
of the tau identification:
\begin{align*}
  \text{Signal efficiency} &= \frac{\text{Number of reconstructed true \tauhadvis passing a selection}}{\text{Total number of reconstructed true \tauhadvis}} \eqcomma \\[0.3em]
  \text{Background rejection} &= \frac{\text{Total number of reconstructed fake \tauhadvis}}{\text{Number of reconstructed fake \tauhadvis passing a selection}} \eqdot
\end{align*}
Notably the efficiencies given in this chapter do not account for
inefficiencies in the reconstruction. The signal efficiency is the efficiency of
selecting \tauhadvis candidates in a signal sample with candidates originating
from hadronic tau lepton decays. The background rejection is the inverse
efficiency of selecting \tauhadvis in a background sample containing fake
\tauhadvis candidates. Hereafter, the signal efficiency and background rejection
will be referred to as efficiency and rejection, respectively. The aim of this
chapter is to improve the rejection of \tauhadvis originating from quark- or
gluon-initiated jets at a fixed signal efficiency such that analyses using tau
identification observe higher signal significances due to a larger
signal-to-background ratio.

\section{Description of the Tau Identification Procedure}
\label{sec:bdt_tauid}
The tau identification algorithm currently in use in the ATLAS experiment
employs BDTs with high-level input variables. The identification uses separate
BDTs for the 1- and 3-prong identification with different sets of input
variables. Classification with BDTs return a score measuring the confidence of
the binary decision. This allows a trade-off between signal efficiency and
background rejection by choosing different decision thresholds. In the ATLAS
experiment these thresholds are derived in bins of the reconstructed visible
transverse momentum~$p_\text{T}$ of the \tauhadvis at tau energy scale and the
average number of interactions per bunch crossing~$\mu$ such that the signal
efficiency is constant in different momentum and pile-up regimes.

\subsection{Discriminating Variables}
\label{sec:bdt_features}

The variables defined in Ref.~\cite{atlas:taurec:run2} are updated to contain
the latest changes in the reconstruction, the largest being the introduction of
the multivariate track classification algorithm. They target the features of
hadronic tau decays discussed in Section~\ref{sec:features_tau_decay}.

Photons originating from neutral pions in hadronic tau lepton decays typically
deposit their energy in the presampler and first two layers of the
electromagnetic calorimeter and energy depositions in EM3 mostly originate from
charged hadrons produced in the tau decay. Therefore, the third layer of the
electromagnetic calorimeter is considered to be part of the hadronic calorimeter
when defining the identification variables. The variables are defined as
follows~\cite{atlas:taurec:run2}:
\begin{description}
\item[Central energy fraction ($f_\text{cent}$):] Fraction of transverse energy
  at EM scale deposited in calorimeter cells with a barycentre in a cone of
  radius $\Delta R < 0.1$, and cells in a cone of radius $\Delta R < 0.2$ with
  respect to the reconstructed tau axis.
  % (i.e.\ the axis after correcting for the position of the primary vertex cf.\
  % section~\ref{sec:reco_vertex_assoc}).
  For noise suppression the calorimeter cells must be part of a
  \emph{TopoCluster}.

\item[Inverse momentum fraction of the leading track
  ($f_\text{leadtrack}^{-1}$):] Fraction of transverse energy at EM scale
  deposited in calorimeter cells (as part of TopoClusters) with a
  barycentre in a cone of radius~$\Delta R < 0.2$ with respect to the tau axis
  and the transverse momentum of the highest transverse momentum track
  classified as \emph{charged} according to the track classification.

\item[Track radius ($R_\text{track}$):] Mean $\Delta R$-distance of tracks
  classified as \emph{charged} and the tau axis weighted by the transverse
  momentum of each track.

\item[Maximum track $\Delta R$ ($\Delta R_\text{max}$):] Maximum
  $\Delta R$-distance of all tracks classified as \emph{charged} with respect to
  the tau axis. Equivalent to $R_\text{track}$ for 1-track \tauhadvis.

\item[Transverse impact parameter significance of the leading track
  ($| S_\text{leadtrack} |$):] Absolute value of the transverse impact parameter
  of the leading \emph{charged} track with respect to the reconstructed primary
  vertex divided by its uncertainty estimate from the track and vertex fit.

\item[Transverse flight path significance ($S_\text{T}^\text{flight}$):]
  Distance between the secondary vertex reconstructed using tracks classified as
  \emph{charged} and primary vertex in the transverse plane divided by the
  estimated uncertainty from the secondary vertex fit. Defined only for
  multi-track \tauhadvis.

\item[Momentum fraction of isolation tracks ($f_\text{iso}^\text{track}$):] Sum
  of transverse momenta of \emph{modified isolation} tracks (cf.\
  Section~\ref{sec:reco_track_sel_classif}) divided by the sum of transverse
  momenta of \emph{modified isolation} and \emph{charged} tracks.

\item[EM energy fraction of charged pions ($f_\text{EM}^\text{track-HAD}$):]
  Energy deposited by charged pions in the electromagnetic part of the
  calorimeter estimated by subtracting the energy contained in the hadronic part
  of the calorimeter (in TopoClusters) from the energy of the track
  system, consisting of tracks classified as \emph{charged}, estimated by the
  scalar sum of track momenta (assuming zero mass). This energy is divided by
  the energy contained in the electromagnetic part of clusters associated with
  the jet seeding the \tauhadvis. All cluster energies are calibrated at LC
  scale.

\item[Ratio of EM energy and track momentum ($f_\text{track}^\text{EM}$):]
  Energy deposited as part of TopoClusters of the reconstructed jet in
  the electromagnetic part of the calorimeter calibrated at LC scale, divided by
  the scalar momentum sum of tracks classified as \emph{charged}.

\item[Fraction of track-plus-EM-system $p_\text{T}$
  ($p_\text{T}^\text{EM+track} / p_\text{T}$):] Transverse momentum of the
  visible tau decay estimated from the four-momentum sum of \emph{charged}
  tracks (assuming $\pi^\pm$ mass) and the two most-energetic clusters (assuming
  zero mass) in the electromagnetic part of the calorimeter, divided by the
  visible transverse momentum of the \tauhadvis at LC scale.

\item[Mass of the track-plus-EM-system ($m_\text{EM+track}$):] Invariant mass of
  the visible tau decay estimated from the four-momentum sum of \emph{charged}
  tracks (assuming $\pi^\pm$ mass) and the two most-energetic clusters (assuming
  zero mass) in the electromagnetic part of the calorimeter.

\item[Mass of the track system ($m_\text{track}$):] Invariant mass of the system
  consisting of tracks classified as \emph{charged} using a $\pi^\pm$ mass
  hypothesis.
\end{description}
The distributions of two important variables for identifying hadronic tau lepton
decays are depicted in Figure~\ref{fig:bdt_discriminants}. The remaining
variables can be found in Appendix~\ref{app:tauid_vars}. The momentum fraction
of isolation tracks~\smash{$f_\text{iso}^\text{track}$} in 1-prong \tauhadvis
candidates shows that isolation tracks often carry a large momentum fraction for
background candidates, while signal candidates often do not have reconstructed
isolation tracks. Moreover, the invariant mass of the track system for 3-prong
\tauhadvis candidates shows a peak for signal candidates below the mass of the
tau lepton, while background candidates can have large invariant masses.
Table~\ref{tab:baseline_variables} summarises the variable selection for the 1-
and 3-prong BDTs.

\begin{figure}[htb]
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/baseline_bdt_vars/1p/SumPtTrkFrac.pdf}
    \subcaption{Momentum fraction of isolation tracks for 1-prong candidates.}
    \label{fig:sumpttrkfrac}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/baseline_bdt_vars/3p/massTrkSys.pdf}
    \subcaption{Mass of the track system for 3-prong candidates.}
    \label{fig:masstrksys}
  \end{subfigure}
  \caption[Examples of variable distributions used for tau
  identification]{Distributions of important variables for tau identification in
    \tauhadvis candidates from simulated \mbox{$\gamma^* \to \tauhad\tauhad$}
    (signal) and dijet (background) events.}
  \label{fig:bdt_discriminants}
\end{figure}

\begin{table}[htb]
  \centering
  {\def\arraystretch{1.35}\small\input{./tables/baseline_variables.tex}}
  \caption[Variables used for tau identification]{Variables used for tau
    identification of \tauhadvis candidates with one or three reconstructed
    \emph{charged} tracks~\cite{atlas:taurec:run2}.}
  \label{tab:baseline_variables}
\end{table}

\subsection{BDT Configuration for Tau Identification}
In the following, the preceding BDT configuration employed by the tau
identification in ATLAS is summarised. At the time of writing, the improvements
presented in this chapter have been partially implemented in the latest
reconstruction release.

The training and evaluation of the tau identification BDTs is performed using
TMVA~\cite{tmva}. The initial configuration uses decision trees limited to a
maximum depth~$d_\text{tree} = 8$. The minimum fraction of training events in a
node considered for further splitting
is~$f_\text{node}^\text{min} = \SI{0.1}{\percent}$. An ensemble
of~$N_\text{trees} = 100$ decision trees is trained using the \emph{AdaBoost}
boosting algorithm with a learning rate~$\beta = 0.2$. Individual decision trees
return estimated class probabilities instead of the majority class and no
\emph{pruning} of statistically insignificant nodes is applied. This
configuration is used as a starting point for further optimisations. The full
configuration of the TMVA-BDTs used in this thesis are summarised in
Appendix~\ref{app:tmva_config}.

\section{Event Simulation, Preselection and Reweighting}
\label{sec:bdt_eventsim}

For training and performance evaluation of the tau identification, simulated
events at a centre-of-mass energy of~$\sqrt{s} = \SI{13}{\TeV}$ and an average
number of interactions per bunch crossing of~$\langle\mu\rangle = \num{30}$ are
used. The signal samples contain~$\gamma^* \to \tauhad \tauhad$ events, where
leptonic tau decays are disabled at generator-level. In contrast to the
Drell--Yan process, no on- and off-shell production and interference with the
$Z$~boson is included. This way a sample of unpolarised tau leptons is created,
which has the same number of positive and negative helicity tau leptons over a
large range of ditau invariant masses. Polarisation biases the angular
distribution of the daughter particles in tau decays, which is not desired when
training general purpose algorithms. Additionally, the ditau invariant mass
spectrum is smooth and decreasing without a large number of events close to the
$Z$~mass, making it convenient for performance studies. The background samples
consist of simulated dijet events, supplying fake \tauhadvis with transverse
momenta of up to \SI{1800}{\GeV}. Both the signal and background samples are
generated using \textsc{Pythia}~8~\cite{pythia82} with the A14
tune~\cite{a14_tune} and the NNPDF23LO PDF set~\cite{NNPDF}. A complete summary
of the simulated samples can be found in Appendix~\ref{app:samples}.

A preselection is applied to reconstructed \tauhadvis in the event samples to
match typical selections applied in analyses. Tau candidates with \tauhadvis
$\pt > \SI{20}{\GeV}$ at tau energy scale, falling in the acceptance range of
the tracking system~$|\eta| < 2.5$, while rejecting \tauhadvis in the transition
region between barrel and end-cap of the
calorimeter~\mbox{$1.37 < |\eta| < 1.52$} and having one or three \emph{charged}
tracks are selected. Additionally, \tauhadvis candidates in the signal samples
are matched to taus at generator-level and the same selections, i.e.\ transverse
momentum, pseudorapidity, number of charged hadrons in the decay, are applied at
truth level \todo{why. potential bias}. The number of tau candidates in the
samples after preselection is summarised in Table~\ref{tab:sample_size}.

\begin{table}[htb]
  \centering
  {\small\input{./tables/sample_size.tex}}
  \caption{Number of \tauhadvis candidates after preselection.}
  \label{tab:sample_size}
\end{table}

In Figure~\ref{fig:pt_mu} the pile-up profile of the simulation and the
distribution of visible transverse momenta of \tauhadvis candidates in the
signal and background samples is shown. Since the samples are created using
different processes, their $p_\text{T}$-spectra differ. When training
identification algorithms it is important to avoid distinguishing signal and
background candidates by their transverse momentum. Therefore, weights are
applied to \tauhadvis candidates in the background sample such that the weighted
background sample is indistinguishable from the signal sample in the
reconstructed transverse momentum.

\begin{figure}[htb]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/pt_mu_samples/mu.pdf}
    \subcaption{Pile-up profile used in the simulation.}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/pt_mu_samples/pt.pdf}
    \subcaption{Transverse momentum distribution of \tauhadvis at tau energy
      scale after preselection.}
  \end{subfigure}
  \caption[Pile-up profile and \pt-spectrum of simulated signal and background
  samples]{Pile-up profile and \pt-spectrum of the simulated signal and
    background samples.}
  \label{fig:pt_mu}
\end{figure}

% \todo[inline]{Reweighting, Quark-Gluon Fraction (3P: \SI{55}{\percent} excluding
%   bottom, \SI{58}{\percent} including bottom) (1P: \SI{55}{\percent} excluding
%   bottom, \SI{59}{\percent} including bottom); approx.\ \SI{60}{\percent}
%   quark-gluon fraction}


\section{Hyperparameter Optimisation}
\label{sec:bdt_hyperparam}

Machine learning algorithms typically have parameters defining the complexity of
the model. They cannot be determined as part of the training process and are
therefore called hyperparameters. Often these parameters need tuning to obtain
the best discriminative power for the underlying problem. In the following the
BDTs of the 1- and 3-prong tau identification are optimised separately with
respect to the boosting algorithm and the most important hyperparameters.

Many input variables have skewed or long-tailed distributions leading to
suboptimal decision trees as TMVA uses equidistant sampling points for finding
the best possible split on a given variable. Therefore, transformations are
applied to the variables to improve the split finding. For this, highly skewed
distributions are log-transformed, while long-tailed distributions and outliers
due to detector resolution effects are clamped to fall into a specified range of
values, meaning values outside of a specified range are set to the lower or
upper limit, respectively. The exact transformations can be found in
Appendix~\ref{app:variable_transforms}.

A so called hold-out validation is used to measure how well the model
generalises to data that was not used to train the model. For this, the signal
and background samples are split into two equally sized samples called training
and testing samples. The training sample is used to train the model and the
testing sample is used to determine the performance characteristics of the
model. Unless otherwise noted, the metrics and figures given in the following
sections are evaluated using the testing sample.

\subsection{Boosting Algorithm}
\label{sec:bdt_boosting}

In Chapter~\ref{sec:ml_boosting} the two boosting algorithms \emph{AdaBoost} and
\emph{Gradient Boosting} are introduced. The performance of both algorithms for
tau identification is compared by training BDTs and varying a boosting-specific
parameter called the learning rate. The learning rate for \emph{AdaBoost} is
typically denoted by~$\beta$, while for gradient boosting it is called the
shrinkage~$\eta$. Reducing the learning rate artificially slows down the
boosting process by decreasing the influence of additional trees on the
ensemble. Empirically it has been found that small learning rates often lead to
improvements in test error~\cite{esl}.

The 1-prong tau identification BDT with the input variables and configuration as
summarised in Section~\ref{sec:bdt_tauid} is trained on signal and background
\tauhadvis candidates. The learning rates for both boosting algorithms are
varied between 0.05 and 1.00 in steps of 0.05. At each setting the background
rejection is calculated at a fixed signal efficiency of~\SI{60}{\percent}. For
this a single cut on the output score of the BDT is determined such
that~\SI{60}{\percent} of \tauhadvis candidates in the signal sample pass this
selection. This is an approximation of the tight working point of the tau
identification used in the ATLAS experiment. The working points will be formally
introduced at a later point.

In Figure~\ref{fig:bdt_boosting_alg} the rejection is shown as a function of the
learning rate for both algorithms. An improvement in rejection of approximately
\SI{10}{\percent} is observed when using \emph{Gradient Boosting}. The likely
reason for this improvement is the more robust loss function (binomial
log-likelihood loss) used in the \emph{Gradient Boosting} implementation of
TMVA~\cite{tmva}. The loss functions are depicted in
Figure~\ref{fig:boosting_loss} showing that the \emph{Gradient Boosting}
implementation puts less emphasis on misclassified events ($y f(x) < 0$)
compared to the exponential loss of \emph{AdaBoost}. This makes \emph{Gradient
  Boosting} a more robust choice for problems where signal and background are
inseparable in certain regions of the input variable space. For tau
identification this can be the case for jets initiated by light quarks, which
more closely resemble hadronic decays of tau leptons. A similar improvement is
observed for the 3-prong identification, therefore \emph{Gradient Boosting} will
be used for further optimisation steps.

\begin{figure}[htb]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/boosting.pdf}
    \subcaption{Rejection of 1-prong \tauhadvis candidates from dijet events
      using BDTs trained with different boosting algorithms.}
    \label{fig:bdt_boosting_alg}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/theory/boosting_loss.pdf}
    \subcaption{Classification losses as a function of the margin~$y f(x)$ with
      the true class~$y \in \{-1, 1\}$ and the BDT response~$f(x) \in [-1, 1]$.
      Adapted from Ref.~\cite{esl}.}
    \label{fig:boosting_loss}
  \end{subfigure}
  \caption[Optimisation of the boosting algorithm]{Optimisation of the boosting
    algorithm used for tau identification.}
\end{figure}

\subsection{Grid Search in Hyperparameter Space}
\label{sec:bdt_grid_search}

Aside from the boosting algorithm, BDTs have other important hyperparameters
that need to be optimised to obtain the best possible performance. These are the
number of trees, $N_\text{trees}$, in the ensemble and the learning rate,
$\eta$. Both parameters are boosting-specific and related as small learning
rates require a large number of trees to converge and vice versa. Additionally,
the maximum tree depth, $d_\text{tree}$, and the fraction of events required for
node splitting, $f_\text{node}^\text{min}$, are important parameters related to
the decision trees in the ensemble. Both parameters limit the depth of trees and
therefore the allowed order of variable interactions (e.g.\ $d_\text{tree} = 2$
allows interactions of up to two variables). The final parameter that is
investigated is \emph{bagged boosting} where each tree is grown using a random
sample of training events drawn with replacement from the full training sample.
This method aims to reduce overfitting, which refers to cases where a model
learns statistical fluctuations in the training sample, thus reducing
generalisation performance. The corresponding hyperparameter is the fraction of
events~$f_\text{bag}$ in the random sample.

These hyperparameters are optimised by forming a grid in the hyperparameter
space and training a BDT for each point on this grid. Subsequently, the
performance of each trained BDT is evaluated. The grid is defined by the
following hyperparameter values
\begin{align*}
  N_\mathrm{trees} &\in \{25, 50, 100, 200, 400, 800\} & \eta &\in \{0.05, 0.1, 0.2, 0.4\} & d_\mathrm{tree} &\in \{4, 6, 8, 12, 16\}\\
  f_\mathrm{node}^\mathrm{min} &\in \{\SI{0.01}{\percent}, \SI{0.1}{\percent},\SI{1.0}{\percent}\} & f_\text{bag} &\in \{\text{None}, \SI{50}{\percent} \}
\end{align*}
resulting in a total of 720 grid points each for the 1- and 3-prong BDT. The
rejection is, analogously to the previous section, calculated using a single cut
on the output score to obtain a signal efficiency comparable to the tight
working point with \SI{60}{\percent} signal efficiency.

In Figure~\ref{fig:hyperparameter_scan_1p} the background rejection of the
1-prong tau identification BDT is shown as a function of the hyperparameters of
the model. The relation between the hyperparameters and their impact on the
background rejection are discussed in the following.

\begin{figure}[htb]
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/gridsearch_1p/scan_MaxDepth_NTrees.pdf}
    \vspace*{-1.6em}
    \subcaption{}
    \label{fig:gridscan_maxdepth_ntrees}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/gridsearch_1p/scan_Shrinkage_NTrees.pdf}
    \vspace*{-1.6em}
    \subcaption{}
    \label{fig:gridscan_shrinkage_ntrees}
  \end{subfigure}
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/gridsearch_1p/scan_Shrinkage_MaxDepth.pdf}
    \vspace*{-1.6em}
    \subcaption{}
    \label{fig:gridscan_shrinkage_maxdepth}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/gridsearch_1p/scan_MinNodeSize_MaxDepth.pdf}
    \vspace*{-1.6em}
    \subcaption{}
    \label{fig:gridscan_minnodesize_maxdepth}
  \end{subfigure}
  \vspace*{-0.3em}
  \caption[Background rejection as a function of BDT hyperparameters
  (1-prong)]{Background rejection of the 1-prong BDT at \SI{60}{\percent} signal
    efficiency as a function of BDT hyperparameters. Bagged boosting with a
    sample fraction~$f_\text{bag} = \SI{50}{\percent}$ is used. The rejection is
    calculated using the testing sample.}
  \label{fig:hyperparameter_scan_1p}
\end{figure}

A distinct trade-off between~$d_\text{tree}$ and~$N_\text{trees}$ can be
observed in Figure~\ref{fig:gridscan_maxdepth_ntrees}, where a large number of
shallow trees and a smaller number of deep trees can reach a similar background
rejection. Figure~\ref{fig:gridscan_shrinkage_ntrees} shows that small learning
rates require more trees to properly fit the model. For a large number of trees
and large maximum tree depths or learning rates the model overfits leading to a
reduced background rejection in the testing sample. This effect can also be
observed in Figure~\ref{fig:gridscan_shrinkage_maxdepth}, where trees with a
depth of 16 can significantly overfit if the learning rate is set too large. The
importance of choosing an appropriate minimum node size is shown in
Figure~\ref{fig:gridscan_minnodesize_maxdepth}. If it is chosen too large the
model does not fully capture the data. However, a small minimum node size can
quickly lead to overfitting for decision trees with large maximum depth. This is
due to the interplay of~$d_\text{tree}$ and~$f_\text{node}^\text{min}$, when
constraining the depth of the decision trees. The optimisation of the 3-prong
tau identification shows similar results, which are summarised in
Appendix~\ref{app:grid_search_3p}.

Table~\ref{tab:bdt_perfs} summarises two configurations for 1- and 3-prong BDTs.
The models denoted by \mbox{BDT A} consist of the BDTs with the largest
rejection at a signal efficiency corresponding to the respective tight working
point. The configurations fall on the edge of the parameter grid, indicating
that a configuration with larger rejection could be found outside of the scanned
hyperparameter region. However, the distributions of the BDT scores for signal
and background \tauhadvis candidates on both the training and testing sample in
Figure~\ref{fig:bdt_score_1p} show a significant deviation between training and
testing sample. This is due to the model learning statistical fluctuations in
the training sample which are not present in the testing sample, indicating that
the models are close to overfitting. These deviations are most significant for
the 1-prong background and the 3-prong signal distributions due to their limited
sample size (cf.\ Table~\ref{tab:sample_size}).

% The one-prong BDT is optimised for efficiency of the tight working-point (in the
% scan no flattening was applied). However the 3-prong BDT was optimised for the
% loose working-point, because the rejection of the 3-prong ID is roughly one
% order of magnitude larger thus the tight working-point is not a stable metric
% considering the size of the available background sample.

\begin{table}[htb]
  \centering
  {\small\input{./tables/bdt_config.tex}}
  \caption[Optimised BDT configurations]{BDT configurations after systematic
    optimisation. BDT~A denotes the BDT with the largest rejection on the
    testing sample, while BDT~B also requires a KS test $p$-value of at least
    \SI{5}{\percent} for compatibility of the BDT score distributions on
    training and testing sample. The rejection is given at \SI{60}{\percent}
    (\SI{45}{\percent}) signal efficiency for the 1-prong (3-prong)
    identification.}
  \label{tab:bdt_perfs}
\end{table}

\begin{figure}[htb]
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/scores/grid_1p0304.pdf}
    \subcaption{BDT A}
    \label{fig:bdt_score_1p}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/scores/grid_1p_subsampling0269.pdf}
    \subcaption{BDT B}
    \label{fig:bdt_score_1p_ks5}
  \end{subfigure}
  \caption[Distribution of the tau identification BDT score
  (1-prong)]{Distributions of the 1-prong tau identification BDT score for the
    training and testing sample for signal and background candidates.}
  \label{fig:bdt_overfitting_scores}
\end{figure}

Instead of choosing the BDT with the largest rejection, compatibility of the BDT
score distributions in the training and testing sample is also required. This is
done to improve the robustness to a potential decrease in training statistics
for future trainings of the tau identification. The compatibility of two
distributions is measured using the $p$-value of the Kolmogorov--Smirnov test
(KS test). The configuration~\mbox{BDT B} in Table~\ref{tab:bdt_perfs} consists
of the BDTs with the highest rejection at the specified signal efficiency, while
also requiring that the $p$-value of the KS test between training and testing
sample is larger than \SI{5}{\percent}. The score distributions after requiring
compatibility according to the KS test are shown in
Figure~\ref{fig:bdt_score_1p_ks5}. For completeness, the distributions for the
3-prong case are summarised in Appendix~\ref{app:bdt_stuff}.

The operating point of a BDT is defined by the threshold applied to its output
score, thus resulting in a trade-off between signal efficiency and background
rejection. Figure~\ref{fig:bdt_rocs} shows the performance characteristics as
the classification threshold is varied and is called the receiver operating
characteristic curve (ROC-curve). Comparing \mbox{BDT A} and \mbox{BDT B} for
the 1- and 3-prong identification, the decrease in rejection of the conservative
model is less than \SI{5}{\percent} for signal efficiencies as low as
\SI{45}{\percent}. Moreover, the rejection of the conservative \mbox{BDT B}
improves on the reference by \num{10} to \SI{16}{\percent}. The rejection of the
3-prong BDT is approximately one order of magnitude larger than for the 1-prong
case. This can largely be attributed to the availablility of invariant mass and
secondary vertex information. Optimising the BDTs for different signal
efficiencies results in similar configurations.

\begin{figure}[htb]
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/roc/bootstrap_roc_comparison_1p.pdf}
    \subcaption{1-prong}
    \label{fig:bdt_1p_roc}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/roc/bootstrap_roc_comparison_3p.pdf}
    \subcaption{3-prong}
    \label{fig:bdt_3p_roc}
  \end{subfigure}
  \caption[ROC-Curve of the optimised BDT]{ROC-Curves for BDT A, BDT B and a
    comparison with the reference configuration. The ratio of the rejection with
    respect to the reference is depicted in the lower panel.}
  \label{fig:bdt_rocs}
\end{figure}

\section{Tau Identification Working Points}
\label{sec:bdt_working_points}

For the use of tau identification in analyses, four working points with fixed
signal efficiencies are defined as shown in Table~\ref{tab:wp_eff}. Due to the
abundance of 3-track \tauhadvis candidates originating from multijet events, a
tighter selection is applied in the 3-prong tau identification. \todo{Very
  loose:analyses with low background or fake factor estimation}

\begin{table}[htb]
  \centering
  {\small\input{./tables/working_point_efficiencies.tex}}
  \caption{Efficiencies of the tau identification working points.}
  \label{tab:wp_eff}
\end{table}

The decision threshold of the BDT is given in bins of the reconstructed
transverse momentum of the \tauhadvis candidate at the tau energy scale and the
average number of interactions per bunch crossing~$\mu$. This is done to ensure
a constant signal efficiency over a wide transverse momentum range and in
different pile-up scenarios. The average number of interactions per bunch
crossing is used instead of the number of reconstructed primary vertices to
ensure compatibility with tau identification at trigger-level, where track and
vertex information is unavailable due time constraints.

The BDT score thresholds are calculated in bins of~\tauhadvis~$p_\text{T}$
and~$\mu$, such that the signal efficiency in each bin reaches the target
efficiency of the respective working point. In
Figure~\ref{fig:working_point_cutmap} the threshold maps are depicted for the
tight working point of the 1- and 3-prong identification using the conservative
\mbox{BDT B}. The binning is chosen such that the derived thresholds are not
dominated by statistical fluctuations due to the limited number of events in
certain bins (cf.\ pile-up profile and \tauhadvis $p_\text{T}$-spectrum in
Figure~\ref{fig:pt_mu}).

\begin{figure}[htb]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/working_points/grid_1p_subsampling0269_wp.pdf}
    \subcaption{1-prong}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/working_points/grid_3p0327_wp.pdf}
    \subcaption{3-prong}
  \end{subfigure}
  \caption[Decision thresholds of the tight working point for the optimised
  BDT]{Decision thresholds for the tight working point using \mbox{BDT B}.}
  \label{fig:working_point_cutmap}
\end{figure}

The dependence of the thresholds on \tauhadvis \pt and $\mu$ is similar for the
1- and 3-prong identification. The thresholds tend to get larger (tighter) with
increasing transverse momentum. This is due to the boost of the tau lepton
leading to larger decay lengths and more collimated daughter particles, thus
making the \tauhadvis candidate more tau-like. At low transverse momenta and
high pile-up the thresholds are looser due to pile-up widening of the decay
signature in the calorimeter. Finally, the dependency of the thresholds on the
amount of pile-up decreases for large transverse momenta, as the soft pile-up
does not significantly alter the signature of decays of highly energetic tau
leptons.

\section{Variable Selection}
\label{sec:bdt_variable_selection}

After optimising the hyperparameter configuration and defining the working
points to be used by analyses, an investigation of the input variable selection
is performed. First the set of variables is extended to improve the rejection of
\tauhadvis candidates from quark- or gluon-initiated jets. Subsequently, input
variables with an insignificant impact on the discriminative power are removed
to simplify the model.

\subsection{Transverse Momentum Dependency of the Input Variables}
\label{sec:bdt_incl_pt}

% Do I need these plots?
% \begin{figure}[ht]
%   \begin{subfigure}[t]{0.48\textwidth}
%     \centering
%     \includegraphics{./figures/bdt_perf/cent_frac_vs_pt_sig.pdf}
%     \subcaption{Signal}
%   \end{subfigure}\hfill
%   \begin{subfigure}[t]{0.48\textwidth}
%     \centering
%     \includegraphics{./figures/bdt_perf/cent_frac_vs_pt_bkg.pdf}
%     \subcaption{Background}
%   \end{subfigure}
%     \caption{$p_\text{T}$-dependency of the central energy fraction.}
%   \label{fig:bdt_pt_dependency}
% \end{figure}

The distributions of the variables used for tau identification change depending
on the reconstructed transverse momentum of the \tauhadvis candidates. This
impacts the identification algorithm as the separation of signal and background
in a given variable may vary as a function of~$p_\text{T}$.

Variables that are strongly affected by this are~$R_\text{track}$ and
$\Delta R_\text{max}$. At large transverse momenta \emph{charged} tracks tend to
be closer to the tau axis for both signal and background candidates, thus
reducing the separation in these variables. Similarly, the central energy
fraction, $f_\text{cent}$, of background candidates increases at high transverse
momentum making them more tau-like. In contrast, the variables based on
invariant masses, $m_\text{track}$ and~$m_\text{EM+track}$, show a larger
separation at high transverse momenta. This is because the mass of signal
candidates is bounded by the mass of the tau lepton when neglecting resolution
effects, while for candidates from quark- or gluon-initiated jets the invariant
mass tends to increase with increasing transverse momentum of the \tauhadvis
candidate. \todo{Plots? Actually not true for mEflowApprox}

To take advantage of the varying signal/background separation in different
$p_\text{T}$-regions, the \tauhadvis transverse momentum is included as an input
to the BDT. Correlations between the remaining input variables and \pt can then
be used to distinguish signal and background candidates. The kinematic
reweighting (cf.\ Section~\ref{sec:bdt_eventsim}) ensures that the
classification only uses correlations of the transverse momentum with the
remaining inputs and not the distinct $p_\text{T}$-spectra of the signal and
background samples.

For the use of tau identification in analyses, the working point efficiencies in
data must be determined in a tag-and-probe measurement. Due to the limited
number of \tauhadvis with transverse momenta greater than \SI{100}{\GeV}, the
efficiency measurement needs to extrapolate to higher $p_\text{T}$-regions.
Therefore, explicit $p_\text{T}$-dependences for transverse momenta larger than
\SI{100}{\GeV} should be avoided. This is realised by clamping the transverse
momentum
\begin{align*}
  p_\text{T}^\text{clamp} = \min(p_\text{T}, \SI{100}{\giga\electronvolt})
\end{align*}
for the use in the BDT. Implicit dependencies cannot be avoided due to the
correlations of the remaining identification variables with the reconstructed
transverse momentum and contribute to the extrapolation uncertainty.

The transverse momentum included in the BDTs is calculated at LC scale. No
tau-specific energy calibration is used to avoid introducing systematic errors
due to the calibration. Moreover, the discriminative power of the identification
does not benefit from using the tau energy scale calibration. In
Table~\ref{tab:bdt_new_variables} the relative rejection gain is summarised
after including the transverse momentum. Including the clamped
momentum~\smash{$p_\text{T}^\text{clamp}$} increases the average rejection by up
to \SI{4.9 +- 0.2}{\percent} for the 1-prong loose, and \SI{3.6 +-
  0.5}{\percent} for the 3-prong medium working point. The comparison of the
relative rejection gain after including the unclamped momentum~$p_\text{T}$ and
the clamped momentum~\smash{$p_\text{T}^\text{clamp}$} show that the majority of
rejection is retained after clamping. \todo{Most stat is below 200 GeV}

Also shown in the table is the rejection after including the momentum fraction
of isolation tracks~$f_\text{iso}^\text{track}$ into the 3-prong BDT, where it
was previously not used. It shows a significant improvement in rejection
especially for the loose and medium working points.

\begin{table}[htb]
  \centering
  {\small\input{./tables/bdt_new_variables.tex}}
  \caption[Relative gain in background rejection after including additional
  variables]{Relative gain in background rejection after including additional
    variables.}
  \label{tab:bdt_new_variables}
\end{table}

\todo[inline]{What else has been tested?}

\subsection{Variable Importance}
\label{sec:bdt_var_importance}

After including~\smash{$p_\text{T}^\text{clamp}$}
and~\smash{$f_\text{iso}^\text{track}$} as inputs to the model, a systematic
evaluation of the variable importances is performed. The aim is to simplify the
model by removing variables with small contributions to the overall
classification power. The importance of individual variables is determined by
training a model without including the variable and calculating the rejection
loss with respect to the baseline model using the full variable set. Doing this
for all input variables allows to rank their importance for discriminating
signal and background \tauhadvis candidates. This method is used, as opposed to
the built-in methods of TMVA, as it properly treats correlated variables.

Figure~\ref{fig:variable_importance} depicts the variable importance for the 1-
and 3-prong BDT. The rejection loss is calculated at the tight working point for
the 1-prong and at the medium working point for the 3-prong BDT. The medium
working point is chosen due to the large rejection of the 3-prong identification
leading to less stable rankings.

\begin{figure}[htb]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/var_importance/1p_iter1.pdf}
    \subcaption{1-prong BDT at the tight working point with
      \SI{60}{\percent}~signal efficiency.}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/var_importance/3p_iter1.pdf}
    \subcaption{3-prong BDT at the medium working point with \SI{60}{\percent}
      signal efficiency.}
  \end{subfigure}
  \caption[Variable importance ranking for the 1- and 3-prong BDT]{Variable
    importance in the 1- and 3-prong BDT. The average rejection loss at the
    specified working point is evaluated on the weighted background sample and
    is calculated with respect to the full variable set. }
  \label{fig:variable_importance}
\end{figure}

The ranking shows that variables sensitive to the decay length of the tau
lepton, i.e.\ $|S_\text{leadtrack}|$ and $S_\text{T}^\text{flight}$, have a
large impact on the classification performance. Moreover,
$f_\text{iso}^\text{track}$ accounts for the majority of the background
rejection in the 1-prong identification. Aside from $S_\text{T}^\text{flight}$
being essential for the 3-prong identification, the invariant
mass~$m_\text{track}$ contributes substantially to the rejection.

The variable importance ranking identifies several weak variables used in the
BDTs such as \smash{$f_\text{EM}^\text{track-HAD}$} in the 1-prong BDT. This is
due to its high correlation
with~\smash{$p_\text{T}^\text{EM+track} / p_\text{T}$} with a linear correlation
coefficient of approximately \SI{70}{\percent} for both signal and background
\tauhadvis candidates. The variable is removed from the BDT and the variable
importance is reevaluated to account for correlations. After
removing~\smash{$f_\text{EM}^\text{track-HAD}$}, the weakest variable
is~$R_\text{track}$ with a rejection loss with respect to the model using the
full variable set of \SI{3.2 +- 0.4}{\percent} when removing it from the BDT.
The variable is kept as the rejection loss deviates by more than three standard
deviations from zero.

Following the same procedure for the 3-prong BDT shows that
removing~$R_\text{track}$, which is highly correlated
with~$\Delta R_\text{max}$, is within one standard deviation of zero rejection
loss and therefore removed from the BDT. Reevaluating the variable importances
identifies~\smash{$f_\text{EM}^\text{track-HAD}$} as the weakest variable with a
rejection loss of \SI{1.2 +- 0.6}{\percent} and is subsequently removed. The
rejection loss incurred in the next iteration exceeds the three standard
deviation threshold, terminating the removal procedure.

The set of variables and their importance after removing weak variables is
summarised in Figure~\ref{fig:variable_importance_final}. The change in input
variables alters the importance ranking slightly, especially affecting variables
that are correlated with variables that were removed (e.g.\
\smash{$p_\text{T}^\text{EM+track} / p_\text{T}$}).

\begin{figure}[htb]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/var_importance/1p_iter2.pdf}
    \subcaption{1-prong BDT at the tight working point with
      \SI{60}{\percent}~signal efficiency.}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/var_importance/3p_iter3.pdf}
    \subcaption{3-prong BDT at the medium working point with
      \SI{60}{\percent}~signal efficiency).}
  \end{subfigure}
  \caption[Variable importance ranking for the 1- and 3-prong BDT after removing
  weak variables]{Variable importance in the 1- and 3-prong BDTs after removing
    weak variables. The average rejection loss at the specified working point is
    evaluated on the weighted background sample and is calculated with respect
    to the full variable set.}
  \label{fig:variable_importance_final}
\end{figure}

% Correlations:
% 1P: ChPiEMEOverCaloEME and ptRatioEflowApprox: sig (bkg) \SI{72}{\percent} (\SI{68}{\percent})
% Other large correlations: etOverPtLeadTrk and EMPOverTrkSysP \SI{86}{\percent} (\SI{90}{\percent})

% 3P: dRmax and innerTrkAvgDist correlation: sig (bkg) \SI{74}{\percent} (\SI{80}{\percent})
% 3P: ChPiEMEOverCaloEME and ptRatioEflowApprox: sig (bkg) \SI{75}{\percent} (\SI{81}{\percent})
% Other large correlations: EMPOverTrkSysP and etOverPtLeadTrk \SI{52}{\percent} (\SI{79}{\percent})

\section{Tau Identification Performance after Optimisation}
\label{sec:bdt_perf}
The performance of the optimised BDT configuration and variable selection is
subsequently evaluated on simulated data and compared with the reference BDTs
before optimisation. The optimisations include the conservative BDT
configurations (BDT B) and the revised variable selection.

Figure~\ref{fig:rejection_comparison} shows the background rejection of the 1-
and 3-prong BDT at the tight working point. After optimisation, the 1-prong BDT
shows an improvement in background rejection of \num{10} to \SI{30}{\percent}
depending on the transverse momentum of the \tauhadvis candidate. The large
rejection of fake \tauhadvis with transverse momentum close to \SI{20}{\GeV} is
due to an increased rejection of \tauhadvis candidates originating from
gluon-initiated jets (cf.\ Appendix~\ref{app:bdt_parton}). \todo{Better
  explanation} Similarly, the improvements for the 3-prong BDT also range from
\num{10} to \SI{30}{\percent}. The other working points show similar
improvements as the tight working point with the exception of the 3-prong loose
working point exceeding the reference by \SI{30}{\percent} for \tauhadvis \pt
larger than \SI{80}{\GeV}. The performance of the loose and medium working
points is summarised in Appendix~\ref{app:bdt_working_point_rejection} for
completeness.

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/post_optimisation/rejection_tight_1p.pdf}
    \subcaption{1-prong}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/post_optimisation/rejection_tight_3p.pdf}
    \subcaption{3-prong}
  \end{subfigure}
  \caption[Background rejection of the tight working point in bins of
  \tauhadvis~\pt for the BDT-based identification after optimisation]{Background
    rejection of the tight working point in bins of \tauhadvis~$p_\text{T}$ at
    tau energy scale.}
  \label{fig:rejection_comparison}
\end{figure}

In Figure~\ref{fig:rejection_highpt} the background rejection is shown over an
extended transverse momentum range. The rejection tends to improve with
increasing \tauhadvis \pt, especially for the 3-prong identification, where
highly boosted taus improve the separation in the transverse flight path
significance and in the track system invariant mass. The 1-prong BDT shows an
improvement exceeding \SI{50}{\percent} at approximately \SI{300}{\GeV}. The
loose and medium working points show smaller improvements at high transverse
momenta. Due to the large rejection of the 3-prong identification, the tight
working point shows improvements of small significance at high transverse
momenta. However, the loose working point shows relative improvements of
\num{50} to more than \SI{100}{\percent} above \SI{200}{\GeV}. For completeness
the rejection over the extended momentum range of the loose and medium working
points is also summarised in Appendix~\ref{app:bdt_working_point_rejection}.
\todo{Write something about missing pixel hits from late tau decay}

\begin{figure}[htbp]
  \centering
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/post_optimisation/1p_highpt/rejection_tight_ratio_highpt.pdf}
    \subcaption{1-prong}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{0.48\textwidth}
    \centering
    \includegraphics{./figures/bdt_perf/post_optimisation/3p_highpt/rejection_tight_ratio_highpt.pdf}
    \subcaption{3-prong}
  \end{subfigure}
  \caption[Background rejection of the tight working point in bins of
  \tauhadvis~\pt for the BDT-based identification after optimisation (extended
  \tauhadvis~\pt range)]{Background rejection of the tight working point in bins
    of \tauhadvis~\pt at tau energy scale over an extended momentum range.}
  \label{fig:rejection_highpt}
\end{figure}

Without large changes in the approach of the current ATLAS tau identification
strategy, a significant improvement in background rejection can be achieved. By
optimising the hyperparameters of the models and revising the variable
selection, an improvement in background rejection of the order of \num{10} to
\SI{30}{\percent} for \tauhadvis candidates with transverse momenta below
\SI{200}{\GeV} can be reached. The rejection of fake \tauhadvis candidates with
$\pt > \SI{200}{\GeV}$ could also be improved significantly for the 1-prong
working points and the 3-prong loose and medium working points.

% 1-prong: Gluon dominated at low pt -- 20 percent quark to gluon ratio sub 25 GeV
% 3-prong:

\todo[inline]{Working point efficiencies for pt and mu\\
  Rejection for full pt range;\\
  Plot 2nd order effects? (e.g.\ ptRatioEflowApprox vs.\ mEflowApprox 1p
  or massTrkSys vs.\ EMPOverTrkSysP 3p); \\
  Understand the rejection vs.\ pt curve. Why does the rejection drop (is it
  because rejection is enhanced due to pile-up fakes)? Why does rejection
  increase again for high pt?; \\
  BDT is optimised for a 'gammatautau'-like spectrum (focused on improving
  rejection at low pt);\\
  Show 2D plot of signal \& background e.g. massTrkSys vs. EMPOverTrkSysP to
  motivate the use of MVA methods / BDTs}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "mythesis"
%%% End:
